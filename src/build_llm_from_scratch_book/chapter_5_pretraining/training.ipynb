{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "import torch\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from torch import nn\n",
    "\n",
    "from src.build_llm_from_scratch_book.dataloader import create_data_loader_v1\n",
    "from src.build_llm_from_scratch_book.loss import calculate_loss_batch, calculate_loss_loader\n",
    "from src.build_llm_from_scratch_book.modules import (\n",
    "    GPTConfig,\n",
    "    GPTModel,\n",
    ")\n",
    "from src.build_llm_from_scratch_book.text import generate_text_simple, text_to_token_ids, token_ids_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(50257, 768)\n",
       "  (positional_embeddings): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size=50257, context_length=256, embed_dim=768, n_heads=12, n_layers=12, drop_rate=0.1, qkv_bias=False\n",
    ")\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(config)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text with untrained model. 10 tokens are, generated, all giberrish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic chief refusing holidays Shannon GamergateHay men methamphetamine\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=config.context_length,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate loss between preds and expected outputs (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate predictions accross 2 input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [16833, 3626, 6100],  # [\"every\", \"effort\" \"moves\"],\n",
    "        [40, 1107, 588],  # [\"I\", \"really\", \"like\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(\n",
    "    [\n",
    "        [3626, 6100, 345],  # [\"effort\", \"moves\", \"you\",\n",
    "        [1107, 588, 11311],  # [\"really\", \"like\", \"chocolate\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape  # batch_size, seq_len (number of tokens), vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[50153],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "print(token_ids.shape)  # shows the last dimension has been reduced to 1 (the token ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this shows that the generated text does not match the target (expected output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  PRESIDENT heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\" f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.6198e-05, 3.1919e-05, 1.1728e-05])\n",
      "Text 2: tensor([1.0538e-05, 5.5378e-05, 4.9063e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate (cross entropy) loss for the proba scores of the two batches relatives to their targets (expected values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding torch.log()\n",
    "\n",
    "In this code, `torch.log()` is used to calculate the natural logarithm (log base e) of the probability values. This is a crucial step in calculating the loss function for training the language model. Here's why:\n",
    "\n",
    "1. **Natural Logarithm**: `torch.log()` computes the natural logarithm of each element in the input tensor. For a probability p, it returns ln(p).\n",
    "\n",
    "2. **Why Use Log Probabilities**:\n",
    "   - Working with log probabilities is numerically more stable than raw probabilities\n",
    "   - When probabilities are very small (like in our case, ranging from ~10^-5 to ~10^-12), their log values are more manageable\n",
    "   - Log probabilities can be added instead of multiplying probabilities, which helps prevent numerical underflow\n",
    "\n",
    "3. **In Our Code**:\n",
    "   - We first calculate probabilities using softmax: `probas = torch.softmax(logits, dim=-1)`\n",
    "   - Then we take the log of these probabilities: `log_probas = torch.log(...)`\n",
    "   - The negative of these log probabilities will be used to compute the cross-entropy loss\n",
    "\n",
    "4. **Example**:\n",
    "   - If a probability is 0.0001 (1e-4)\n",
    "   - Its log value would be approximately -9.21\n",
    "   - This is why we see negative values in our output tensor (like -9.4822, -10.3523, etc.)\n",
    "\n",
    "This transformation is a standard step in training neural networks for classification tasks, particularly in language modeling where we need to handle many small probability values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.4822, -10.3523, -11.3535, -11.4605,  -9.8013, -12.2250])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the average of the log probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7791)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to get the average log probability as close to 0 as possible by updating the model’s weights as part of the training process. However, in deep learning, the common practice isn’t to push the average log probability up to 0 but rather to bring the negative average log probability down to 0. The negative average log probability is simply the average log probability multiplied by –1. \n",
    "\n",
    "This is the cross-entropy loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7791)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cross entropy with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourself of the dimensions of the predicted logits and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape don't match, so the tensors need flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # combines the dimensions 0 and 1 -> the batches disappear, we have only tokens\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once flattened, we can apply cross-entropy loss and we see the results are the same as the manual step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7791)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the short story to train LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with Path(file_path).open(\"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing some stats about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the data splitting and loading, we first define a train_ratio to use 90% of the data for training and the remaining 10% as validation data for model evaluation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_data_loader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    context_window_size=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "val_loader = create_data_loader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    context_window_size=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the data loaders to make sure they are loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate loss with loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.990696377224392\n",
      "Validation loss: 10.985530853271484\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calculate_loss_loader(train_loader, model, device)\n",
    "    val_loss = calculate_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calculate_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calculate_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(\n",
    "    model: nn.Module, tokenizer: tiktoken.Encoding, device: torch.device, start_context: int\n",
    ") -> None:\n",
    "    \"\"\"Generate and print sample.\"\"\"\n",
    "    model.eval()\n",
    "    context_size = model.positional_embeddings.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(  # noqa: PLR0913\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.AdamW,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: int,\n",
    "    eval_iter: int,\n",
    "    start_context: str,\n",
    "    tokenizer: tiktoken.Encoding,\n",
    ") -> tuple[list[float], list[float], list[int]]:\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.820, Val loss 9.962\n",
      "Ep 1 (Step 000005): Train loss 7.963, Val loss 8.282\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(cfg=config)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "# num_epochs = 10\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(\n",
    "    epochs_seen: torch.Tensor, tokens_seen: list[int], train_losses: list[float], val_losses: list[float]\n",
    ") -> None:\n",
    "    \"\"\"Plot the losses.\"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding strategies / randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(50257, 768)\n",
       "  (positional_embeddings): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugin GPTModel instance into generate_text_simple func. We can run this multiple times and since the probas do not change,\n",
    "the same output text is generated every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=config.context_length,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing argmax (that selects the item with highest proba) with multinomial (selects from distribution of highest probas).\n",
    "This leads to more variety in produced results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123) \n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate this is indeed selecting, let's repeat the operation 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas) -> None:\n",
    "    \"\"\"Select amongst probas, 1000 times to illustrate temperature.\"\"\"\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "             for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
