{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "import torch\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from torch import nn\n",
    "\n",
    "from src.build_llm_from_scratch_book.dataloader import create_data_loader_v1\n",
    "from src.build_llm_from_scratch_book.loss import calculate_loss_batch, calculate_loss_loader\n",
    "from src.build_llm_from_scratch_book.modules import (\n",
    "    GPTConfig,\n",
    "    GPTModel,\n",
    ")\n",
    "from src.build_llm_from_scratch_book.text import generate_text_simple, text_to_token_ids, token_ids_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(50257, 768)\n",
       "  (positional_embeddings): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size=50257, context_length=256, embed_dim=768, n_heads=12, n_layers=12, drop_rate=0.1, qkv_bias=False\n",
    ")\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(config)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text with untrained model. 10 tokens are, generated, all giberrish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic chief refusing holidays Shannon GamergateHay men methamphetamine\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=config.context_length,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate loss between preds and expected outputs (targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate predictions accross 2 input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [16833, 3626, 6100],  # [\"every\", \"effort\" \"moves\"],\n",
    "        [40, 1107, 588],  # [\"I\", \"really\", \"like\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(\n",
    "    [\n",
    "        [3626, 6100, 345],  # [\"effort\", \"moves\", \"you\",\n",
    "        [1107, 588, 11311],  # [\"really\", \"like\", \"chocolate\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape  # batch_size, seq_len (number of tokens), vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[50153],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "print(token_ids.shape)  # shows the last dimension has been reduced to 1 (the token ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this shows that the generated text does not match the target (expected output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  PRESIDENT heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\" f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.6198e-05, 3.1919e-05, 1.1728e-05])\n",
      "Text 2: tensor([1.0538e-05, 5.5378e-05, 4.9063e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate (cross entropy) loss for the proba scores of the two batches relatives to their targets (expected values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding torch.log()\n",
    "\n",
    "In this code, `torch.log()` is used to calculate the natural logarithm (log base e) of the probability values. This is a crucial step in calculating the loss function for training the language model. Here's why:\n",
    "\n",
    "1. **Natural Logarithm**: `torch.log()` computes the natural logarithm of each element in the input tensor. For a probability p, it returns ln(p).\n",
    "\n",
    "2. **Why Use Log Probabilities**:\n",
    "   - Working with log probabilities is numerically more stable than raw probabilities\n",
    "   - When probabilities are very small (like in our case, ranging from ~10^-5 to ~10^-12), their log values are more manageable\n",
    "   - Log probabilities can be added instead of multiplying probabilities, which helps prevent numerical underflow\n",
    "\n",
    "3. **In Our Code**:\n",
    "   - We first calculate probabilities using softmax: `probas = torch.softmax(logits, dim=-1)`\n",
    "   - Then we take the log of these probabilities: `log_probas = torch.log(...)`\n",
    "   - The negative of these log probabilities will be used to compute the cross-entropy loss\n",
    "\n",
    "4. **Example**:\n",
    "   - If a probability is 0.0001 (1e-4)\n",
    "   - Its log value would be approximately -9.21\n",
    "   - This is why we see negative values in our output tensor (like -9.4822, -10.3523, etc.)\n",
    "\n",
    "This transformation is a standard step in training neural networks for classification tasks, particularly in language modeling where we need to handle many small probability values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.4822, -10.3523, -11.3535, -11.4605,  -9.8013, -12.2250])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the average of the log probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7791)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to get the average log probability as close to 0 as possible by updating the model’s weights as part of the training process. However, in deep learning, the common practice isn’t to push the average log probability up to 0 but rather to bring the negative average log probability down to 0. The negative average log probability is simply the average log probability multiplied by –1. \n",
    "\n",
    "This is the cross-entropy loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7791)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cross entropy with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourself of the dimensions of the predicted logits and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape don't match, so the tensors need flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # combines the dimensions 0 and 1 -> the batches disappear, we have only tokens\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once flattened, we can apply cross-entropy loss and we see the results are the same as the manual step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7791)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the short story to train LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with Path(file_path).open(\"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing some stats about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the data splitting and loading, we first define a train_ratio to use 90% of the data for training and the remaining 10% as validation data for model evaluation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_data_loader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    context_window_size=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "val_loader = create_data_loader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    context_window_size=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the data loaders to make sure they are loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate loss with loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.990696377224392\n",
      "Validation loss: 10.985530853271484\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calculate_loss_loader(train_loader, model, device)\n",
    "    val_loss = calculate_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calculate_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calculate_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(\n",
    "    model: nn.Module, tokenizer: tiktoken.Encoding, device: torch.device, start_context: int\n",
    ") -> None:\n",
    "    \"\"\"Generate and print sample.\"\"\"\n",
    "    model.eval()\n",
    "    context_size = model.positional_embeddings.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(  # noqa: PLR0913\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: torch.optim.AdamW,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: int,\n",
    "    eval_iter: int,\n",
    "    start_context: str,\n",
    "    tokenizer: tiktoken.Encoding,\n",
    ") -> tuple[list[float], list[float], list[int]]:\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.820, Val loss 9.962\n",
      "Ep 1 (Step 000005): Train loss 7.963, Val loss 8.282\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Ep 2 (Step 000010): Train loss 6.660, Val loss 7.053\n",
      "Ep 2 (Step 000015): Train loss 5.975, Val loss 6.582\n",
      "Every effort moves you. \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
      "Ep 3 (Step 000020): Train loss 11.711, Val loss 12.092\n",
      "Ep 3 (Step 000025): Train loss 5.675, Val loss 6.529\n",
      "Every effort moves you.                                                 \n",
      "Ep 4 (Step 000030): Train loss 5.451, Val loss 6.441\n",
      "Ep 4 (Step 000035): Train loss 5.170, Val loss 6.443\n",
      "Every effort moves you. \"I that my and he was his the \" my my. \"I was his pictures--and it was the \" of the\"I the of the of the \" the \" his of the of the of the \"I\n",
      "Ep 5 (Step 000040): Train loss 4.738, Val loss 6.300\n",
      "Every effort moves you. \"Oh, I had been the picture.  \"I I had been--and's--and, I had been to the picture.  \"I at the room. \"I have a little the room, I had\n",
      "Ep 6 (Step 000045): Train loss 3.694, Val loss 6.242\n",
      "Ep 6 (Step 000050): Train loss 3.703, Val loss 6.249\n",
      "Every effort moves you know the end.   \"Oh, the fact with a little a little, I had been--and here are the end you know it.     \"--and I had the fact, the fact--I had been\n",
      "Ep 7 (Step 000055): Train loss 3.215, Val loss 6.244\n",
      "Ep 7 (Step 000060): Train loss 2.825, Val loss 6.118\n",
      "Every effort moves you know,\" he had been the fact of the fact, and I had been I had been--his, and I was, and I had been the moment--as Jack himself, and he was his own of the fact--his, and I had\n",
      "Ep 8 (Step 000065): Train loss 2.411, Val loss 6.155\n",
      "Ep 8 (Step 000070): Train loss 2.100, Val loss 6.160\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, and that, and Mrs.   \"I turned; and I saw that, and down the room, the first\n",
      "Ep 9 (Step 000075): Train loss 1.648, Val loss 6.222\n",
      "Ep 9 (Step 000080): Train loss 1.333, Val loss 6.278\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. \"Oh, and I had been at my elbow and as he had been the man of the hour. \n",
      "Ep 10 (Step 000085): Train loss 1.004, Val loss 6.343\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"    \"--it was his pictures with a little. \"It's his pictures with a fashionable painter--that I found\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(cfg=config)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "# num_epochs = 10\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(\n",
    "    epochs_seen: torch.Tensor, tokens_seen: list[int], train_losses: list[float], val_losses: list[float]\n",
    ") -> None:\n",
    "    \"\"\"Plot the losses.\"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding strategies / randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(50257, 768)\n",
       "  (positional_embeddings): Embedding(256, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
